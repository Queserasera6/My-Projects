{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "186a9f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bayesian-optimization\n",
      "  Obtaining dependency information for bayesian-optimization from https://files.pythonhosted.org/packages/c5/fd/5998d2f9d693b5ef2954e3d9ddb96ede395373faa5d9bcfbd7da4b945d47/bayesian_optimization-1.5.1-py3-none-any.whl.metadata\n",
      "  Using cached bayesian_optimization-1.5.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: catboost in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (from bayesian-optimization) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.25 in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (from bayesian-optimization) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.0.0 in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (from bayesian-optimization) (1.3.0)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.0.0 in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (from bayesian-optimization) (1.11.1)\n",
      "Requirement already satisfied: graphviz in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (from catboost) (3.7.2)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (from catboost) (2.0.3)\n",
      "Requirement already satisfied: plotly in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (2.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (from matplotlib->catboost) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (from matplotlib->catboost) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (from matplotlib->catboost) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\olasunkanmi mubarak\\anacon\\lib\\site-packages (from plotly->catboost) (8.2.2)\n",
      "Using cached bayesian_optimization-1.5.1-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: bayesian-optimization\n",
      "Successfully installed bayesian-optimization-1.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bayesian-optimization catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1fc173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "756b9abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('Train Dataset .csv')\n",
    "X_data = df1.drop(['Id','target'], axis=1)\n",
    "y_data = df1['target']\n",
    "X , X_test, y, y_test = train_test_split(X_data, y_data,test_size = 0.2, random_state = 40)\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X,y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e06c649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | border... |   depth   | iterat... | l2_lea... | learni... | random... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.811    \u001b[39m | \u001b[39m0.3745   \u001b[39m | \u001b[39m242.5    \u001b[39m | \u001b[39m8.392    \u001b[39m | \u001b[39m602.7    \u001b[39m | \u001b[39m2.404    \u001b[39m | \u001b[39m0.05524  \u001b[39m | \u001b[39m0.05808  \u001b[39m |\n",
      "| \u001b[35m2        \u001b[39m | \u001b[35m0.814    \u001b[39m | \u001b[35m0.8662   \u001b[39m | \u001b[35m153.7    \u001b[39m | \u001b[35m8.248    \u001b[39m | \u001b[35m30.38    \u001b[39m | \u001b[35m9.729    \u001b[39m | \u001b[35m0.2514   \u001b[39m | \u001b[35m0.2123   \u001b[39m |\n",
      "| \u001b[35m3        \u001b[39m | \u001b[35m0.816    \u001b[39m | \u001b[35m0.1818   \u001b[39m | \u001b[35m47.58    \u001b[39m | \u001b[35m5.825    \u001b[39m | \u001b[35m529.5    \u001b[39m | \u001b[35m4.888    \u001b[39m | \u001b[35m0.09446  \u001b[39m | \u001b[35m0.6119   \u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.8138   \u001b[39m | \u001b[39m0.1395   \u001b[39m | \u001b[39m75.2     \u001b[39m | \u001b[39m6.198    \u001b[39m | \u001b[39m461.5    \u001b[39m | \u001b[39m8.067    \u001b[39m | \u001b[39m0.06791  \u001b[39m | \u001b[39m0.5142   \u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.8125   \u001b[39m | \u001b[39m0.5924   \u001b[39m | \u001b[39m12.8     \u001b[39m | \u001b[39m7.645    \u001b[39m | \u001b[39m178.8    \u001b[39m | \u001b[39m1.585    \u001b[39m | \u001b[39m0.2852   \u001b[39m | \u001b[39m0.9656   \u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.8158   \u001b[39m | \u001b[39m0.8084   \u001b[39m | \u001b[39m78.37    \u001b[39m | \u001b[39m4.586    \u001b[39m | \u001b[39m687.4    \u001b[39m | \u001b[39m4.961    \u001b[39m | \u001b[39m0.04539  \u001b[39m | \u001b[39m0.4952   \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.81     \u001b[39m | \u001b[39m0.03439  \u001b[39m | \u001b[39m232.0    \u001b[39m | \u001b[39m5.553    \u001b[39m | \u001b[39m665.9    \u001b[39m | \u001b[39m3.805    \u001b[39m | \u001b[39m0.1608   \u001b[39m | \u001b[39m0.5467   \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m0.8068   \u001b[39m | \u001b[39m0.1849   \u001b[39m | \u001b[39m247.3    \u001b[39m | \u001b[39m8.651    \u001b[39m | \u001b[39m940.1    \u001b[39m | \u001b[39m9.053    \u001b[39m | \u001b[39m0.1834   \u001b[39m | \u001b[39m0.9219   \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.816    \u001b[39m | \u001b[39m0.08849  \u001b[39m | \u001b[39m50.78    \u001b[39m | \u001b[39m4.271    \u001b[39m | \u001b[39m332.1    \u001b[39m | \u001b[39m4.498    \u001b[39m | \u001b[39m0.08869  \u001b[39m | \u001b[39m0.8287   \u001b[39m |\n"
     ]
    }
   ],
   "source": [
    "# Define the function to optimize\n",
    "def catboost_cv(depth, learning_rate, iterations, l2_leaf_reg, border_count, \n",
    "                bagging_temperature, random_strength):\n",
    "    # Convert parameters to integers where necessary\n",
    "    depth = int(depth)\n",
    "    iterations = int(iterations)\n",
    "    l2_leaf_reg = int(l2_leaf_reg)\n",
    "    border_count = int(border_count)\n",
    "    \n",
    "    # Create the CatBoost model with the given parameters\n",
    "    model = CatBoostClassifier(\n",
    "        verbose=False,\n",
    "        random_state=42,\n",
    "        scale_pos_weight=5,\n",
    "        depth=depth,\n",
    "        learning_rate=learning_rate,\n",
    "        iterations=iterations,\n",
    "        l2_leaf_reg=l2_leaf_reg,\n",
    "        border_count=border_count,\n",
    "        bagging_temperature=bagging_temperature,\n",
    "        random_strength=random_strength\n",
    "    )\n",
    "\n",
    "    # Cross-validation setup\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Use negative log loss as the scoring metric (change to your preferred metric)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    # Return the mean score\n",
    "    return scores.mean()\n",
    "\n",
    "# Define the bounds for Bayesian Optimization\n",
    "param_bounds = {\n",
    "    'depth': (4, 10),\n",
    "    'learning_rate': (0.01, 0.3),\n",
    "    'iterations': (10, 1000),\n",
    "    'l2_leaf_reg': (1, 10),\n",
    "    'border_count': (1, 255),\n",
    "    'bagging_temperature': (0.0, 1.0),\n",
    "    'random_strength': (0.0, 1.0)\n",
    "}\n",
    "\n",
    "# Create the Bayesian Optimization object\n",
    "optimizer = BayesianOptimization(\n",
    "    f=catboost_cv,\n",
    "    pbounds=param_bounds,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Perform the optimization\n",
    "optimizer.maximize(init_points=10, n_iter=30)  # `init_points` sets random exploration; `n_iter` is the number of optimization steps.\n",
    "\n",
    "# Extract the best parameters\n",
    "best_params = optimizer.max['params']\n",
    "best_params['depth'] = int(best_params['depth'])  # Ensure integer type for certain parameters\n",
    "best_params['iterations'] = int(best_params['iterations'])\n",
    "best_params['l2_leaf_reg'] = int(best_params['l2_leaf_reg'])\n",
    "best_params['border_count'] = int(best_params['border_count'])\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d9060b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = CatBoostClassifier(\n",
    "    verbose=False,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=5,\n",
    "    depth=best_params['depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    iterations=best_params['iterations'],\n",
    "    l2_leaf_reg=best_params['l2_leaf_reg'],\n",
    "    border_count=best_params['border_count'],\n",
    "    bagging_temperature=best_params['bagging_temperature'],\n",
    "    random_strength=best_params['random_strength']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70569caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.04%\n",
      "Confusion Matrix:\n",
      " [[  21  260]\n",
      " [  17 1163]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.07      0.13       281\n",
      "           1       0.82      0.99      0.89      1180\n",
      "\n",
      "    accuracy                           0.81      1461\n",
      "   macro avg       0.68      0.53      0.51      1461\n",
      "weighted avg       0.77      0.81      0.75      1461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_prob_ = best_model.predict_proba(X_test)  # Predicting probabilities\n",
    "y_pred_ = np.argmax(y_prob_, axis=1)\n",
    "accuracy_ = accuracy_score(y_test, y_pred_)\n",
    "conf_matrix_ = confusion_matrix(y_test, y_pred_)\n",
    "classification_rep_ = classification_report(y_test, y_pred_)\n",
    "\n",
    "print(f'Accuracy: {accuracy_ * 100:.2f}%')\n",
    "print('Confusion Matrix:\\n', conf_matrix_)\n",
    "print('Classification Report:\\n', classification_rep_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adfcfea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.35%\n",
      "Confusion Matrix:\n",
      " [[ 57 155]\n",
      " [ 63 894]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.27      0.34       212\n",
      "           1       0.85      0.93      0.89       957\n",
      "\n",
      "    accuracy                           0.81      1169\n",
      "   macro avg       0.66      0.60      0.62      1169\n",
      "weighted avg       0.78      0.81      0.79      1169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prob = best_model.predict_proba(X_cv)[:, 1] # Predicting probabilities\n",
    "y_pred = np.where(y_prob > 0.70, 1, 0)\n",
    "accuracy = accuracy_score(y_cv, y_pred)\n",
    "conf_matrix = confusion_matrix(y_cv, y_pred)\n",
    "classification_rep = classification_report(y_cv, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "print('Confusion Matrix:\\n', conf_matrix)\n",
    "print('Classification Report:\\n', classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad7a01ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv('Test Dataset.csv')\n",
    "df3.rename(columns = {'age' : 'Age', 'sex': 'Sex'}, inplace = True)\n",
    "X_test_real = df3.drop(['id'], axis=1)\n",
    "\n",
    "\n",
    "y_pred_real = best_model.predict_proba(X_test_real)\n",
    "y_pred_1 = np.argmax(y_pred_real, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e9a2100",
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission = pd.DataFrame({'ID' : df3['id'], 'target' : y_pred_1})\n",
    "Submission.to_csv('DSNSubmission_12.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
